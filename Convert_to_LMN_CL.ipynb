{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa01555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "#import logging\n",
    "# from pyspedas.cotrans.cotrans_get_coord import cotrans_get_coord\n",
    "# from pyspedas.cotrans.cotrans import cotrans\n",
    "# from pyspedas.cotrans.gsm2lmn import gsm2lmn\n",
    "from pyspedas.mms import mec\n",
    "#from pyspedas import tinterpol, omni\n",
    "import os\n",
    "import pyspedas\n",
    "from pytplot import tplot, get_data, store_data, tlimit, options,tplot_names\n",
    "from pyspedas.mms import fpi,fgm\n",
    "#from pyspedas.mms.mms_orbit_plot import mms_orbit_plot\n",
    "\n",
    "# logging.captureWarnings(True)\n",
    "# logging.basicConfig(format='%(asctime)s: %(message)s', datefmt='%d-%b-%y %H:%M:%S', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879898fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MMS2_B = pd.read_csv('MMS2_B.csv',header = 0,names = ['times','Bx','By','Bz','Bmag','date'],\n",
    "                     parse_dates=['date'])\n",
    "\n",
    "\n",
    "MMS2_V = pd.read_csv('MMS2_V.csv',\n",
    "                     header = 0,names = ['times','Vx','Vy','Vz','date'],\n",
    "                     parse_dates=['date'])\n",
    "\n",
    "MMS2_n = pd.read_csv('MMS2_n.csv',\n",
    "                     header = 0,names = ['times','n','date'],\n",
    "                     parse_dates=['date'])\n",
    "\n",
    "MMS2_Tperp = pd.read_csv('MMS2_Tperp.csv',\n",
    "                     header = 0,names = ['times','Tperp','date'],\n",
    "                     parse_dates=['date'])\n",
    "\n",
    "MMS2_Tpara = pd.read_csv('MMS2_Tpara.csv',\n",
    "                     header = 0,names = ['times','Tpara','date'],\n",
    "                     parse_dates=['date'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4c64aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>Bx</th>\n",
       "      <th>By</th>\n",
       "      <th>Bz</th>\n",
       "      <th>Bmag</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.592426e+09</td>\n",
       "      <td>6.831184</td>\n",
       "      <td>2.097465</td>\n",
       "      <td>8.011147</td>\n",
       "      <td>10.735126</td>\n",
       "      <td>2020-06-17 20:29:23.249434112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.592426e+09</td>\n",
       "      <td>6.841014</td>\n",
       "      <td>2.092012</td>\n",
       "      <td>8.037822</td>\n",
       "      <td>10.760231</td>\n",
       "      <td>2020-06-17 20:29:23.257246976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.592426e+09</td>\n",
       "      <td>6.823400</td>\n",
       "      <td>2.076468</td>\n",
       "      <td>8.044454</td>\n",
       "      <td>10.750989</td>\n",
       "      <td>2020-06-17 20:29:23.265059072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.592426e+09</td>\n",
       "      <td>6.798868</td>\n",
       "      <td>2.074919</td>\n",
       "      <td>8.046974</td>\n",
       "      <td>10.737024</td>\n",
       "      <td>2020-06-17 20:29:23.272871936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.592426e+09</td>\n",
       "      <td>6.819839</td>\n",
       "      <td>2.061433</td>\n",
       "      <td>8.057381</td>\n",
       "      <td>10.755514</td>\n",
       "      <td>2020-06-17 20:29:23.280684032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308347</th>\n",
       "      <td>1.592444e+09</td>\n",
       "      <td>2.217578</td>\n",
       "      <td>2.958381</td>\n",
       "      <td>8.717915</td>\n",
       "      <td>9.469515</td>\n",
       "      <td>2020-06-18 01:30:02.413986048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308348</th>\n",
       "      <td>1.592444e+09</td>\n",
       "      <td>2.205297</td>\n",
       "      <td>2.972957</td>\n",
       "      <td>8.730649</td>\n",
       "      <td>9.482935</td>\n",
       "      <td>2020-06-18 01:30:02.421797888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308349</th>\n",
       "      <td>1.592444e+09</td>\n",
       "      <td>2.226805</td>\n",
       "      <td>2.989825</td>\n",
       "      <td>8.726459</td>\n",
       "      <td>9.489406</td>\n",
       "      <td>2020-06-18 01:30:02.429611008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308350</th>\n",
       "      <td>1.592444e+09</td>\n",
       "      <td>2.229691</td>\n",
       "      <td>2.994750</td>\n",
       "      <td>8.727658</td>\n",
       "      <td>9.492738</td>\n",
       "      <td>2020-06-18 01:30:02.437423104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308351</th>\n",
       "      <td>1.592444e+09</td>\n",
       "      <td>2.223140</td>\n",
       "      <td>2.979639</td>\n",
       "      <td>8.719428</td>\n",
       "      <td>9.478873</td>\n",
       "      <td>2020-06-18 01:30:02.445235968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2308352 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                times        Bx        By        Bz       Bmag  \\\n",
       "0        1.592426e+09  6.831184  2.097465  8.011147  10.735126   \n",
       "1        1.592426e+09  6.841014  2.092012  8.037822  10.760231   \n",
       "2        1.592426e+09  6.823400  2.076468  8.044454  10.750989   \n",
       "3        1.592426e+09  6.798868  2.074919  8.046974  10.737024   \n",
       "4        1.592426e+09  6.819839  2.061433  8.057381  10.755514   \n",
       "...               ...       ...       ...       ...        ...   \n",
       "2308347  1.592444e+09  2.217578  2.958381  8.717915   9.469515   \n",
       "2308348  1.592444e+09  2.205297  2.972957  8.730649   9.482935   \n",
       "2308349  1.592444e+09  2.226805  2.989825  8.726459   9.489406   \n",
       "2308350  1.592444e+09  2.229691  2.994750  8.727658   9.492738   \n",
       "2308351  1.592444e+09  2.223140  2.979639  8.719428   9.478873   \n",
       "\n",
       "                                 date  \n",
       "0       2020-06-17 20:29:23.249434112  \n",
       "1       2020-06-17 20:29:23.257246976  \n",
       "2       2020-06-17 20:29:23.265059072  \n",
       "3       2020-06-17 20:29:23.272871936  \n",
       "4       2020-06-17 20:29:23.280684032  \n",
       "...                               ...  \n",
       "2308347 2020-06-18 01:30:02.413986048  \n",
       "2308348 2020-06-18 01:30:02.421797888  \n",
       "2308349 2020-06-18 01:30:02.429611008  \n",
       "2308350 2020-06-18 01:30:02.437423104  \n",
       "2308351 2020-06-18 01:30:02.445235968  \n",
       "\n",
       "[2308352 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MMS2_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a708228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652377\n",
      "652761\n",
      "6.2794053335937505\n",
      "7.2512223664062505\n"
     ]
    }
   ],
   "source": [
    "# supply the current sheet start time and end time:\n",
    "CS_st_t = '2020-06-17/21:54:23'\n",
    "\n",
    "\n",
    "CS_end_t = '2020-06-17/21:54:35'\n",
    "\n",
    "\n",
    "# time period before CS to take average of B-field:\n",
    "st_ave_B1 = '2020-06-17/21:54:20'\n",
    "end_ave_B1 = '2020-06-17/21:54:23'\n",
    "\n",
    "st_ave_B2 = '2020-06-17/21:54:35'\n",
    "end_ave_B2 = '2020-06-17/21:54:38'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st_idx_B1 = MMS2_B.date.searchsorted(st_ave_B1)\n",
    "end_idx_B1 = MMS2_B.date.searchsorted(end_ave_B1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st_idx_B2 = MMS2_B.date.searchsorted(st_ave_B2)\n",
    "end_idx_B2 = MMS2_B.date.searchsorted(end_ave_B2)\n",
    "\n",
    "\n",
    "print(st_idx_B1)\n",
    "print(end_idx_B1)\n",
    "\n",
    "Bz1 = np.array(pd.to_numeric(MMS2_B['Bz']))\n",
    "ave_B1 = np.mean(Bz1[st_idx_B1:end_idx_B1])\n",
    "\n",
    "print(ave_B1)\n",
    "Bz2 = np.array(pd.to_numeric(MMS2_B['Bz']))\n",
    "ave_B2 = np.mean(Bz2[st_idx_B2:end_idx_B2])\n",
    "\n",
    "print(ave_B2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     end_idx_B = MMS2_B.date.searchsorted(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a161e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "'''\n",
    "Take in magnetic field dataframe mag_arr e.g., 'MMS2_b.csv'\n",
    "Take in specified start time (m1) of current sheet e.g., '2020-06-17/21:54:20'\n",
    "\n",
    "take in specified end time (m2) of current sheet crossing e.g., '2020-06-17/21:54:23'\n",
    "\n",
    "Code from Eriksson\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# In summary, the minimum variance analysis consists of constructing the matrix M_{μν}^{B}, \n",
    "# defined by equation 8.8 in terms of the measured field data and the cartesian coordinate \n",
    "# system in which the measured data are represented, and then finding the three eigenvalues λi, \n",
    "# and corresponding eigenvectors xi, of the matrix. The eigenvector x3 corresponding to the \n",
    "# smallest eigenvalue, λ3, is used as the estimator for the vector normal to the current sheet \n",
    "# and λ3 itself represents the variance of the magnetic field component along the estimated normal. \n",
    "# The eigenvectors x1 and x2, corresponding to maximum and intermediate variance, are then tangential \n",
    "# to the transition layer and the set {x1,x2,x3} arranged as a right-handed orthonormal triad provides \n",
    "# suitable basis vectors for the local coordinates (x,y,z) discussed in connection with equation 8.1.\n",
    "\n",
    "# #This function performs the minimum variance analysis for\n",
    "# #the magnetic field between times m1 and m2 to get an L,M,N\n",
    "# #coordinate system\n",
    "# # ex. m1='2001-02-04/21:40:00'\n",
    "# #\n",
    "# # reference: Sonnerup, B. U. O., and M. Scheible, Minimum and maximum variance\n",
    "# #\t     analysis, in Analysis methods for multi-spacecraft data, edited by\n",
    "# #\t     G. Paschmann and P. W. Daly, ISSI Sci. Rep., SR-001, p. 185-220,\n",
    "# #\t     ESA Publications Division, Noordwijk, The Netherlands, 1998.\n",
    "# #\t     (see ~eriksson/papers/issi_analysis_methods.pdf)\n",
    "\n",
    "# #########################\n",
    "# #GET MAGNETIC FIELD DATA#\n",
    "# #########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mms_mvab(m1,m2,mag_arr_str):\n",
    "    mag_arr = pd.read_csv(mag_arr_str,header = 0,names = ['times','Bx','By','Bz','Bmag','date'],\n",
    "                         parse_dates=['date'])\n",
    "    \n",
    "    m1 = pd.to_datetime(m1)\n",
    "    m2 = pd.to_datetime(m2)\n",
    "    \n",
    "    # ##########################################################\n",
    "    # Check for NaN values\n",
    "    NaNs = mag_arr.isnull().values.any()\n",
    "\n",
    "    if NaNs == True:\n",
    "        print,'Nans were found: '\n",
    "        print, mag_arr.isnull().values.any()\n",
    "        print,'Replacing with average of surrounding data pts '\n",
    "        # Indices of NaNs in each component\n",
    "        NaNs_Bx = np.argwhere(np.isnan(bx))\n",
    "        NaNs_By = np.argwhere(np.isnan(by))\n",
    "        NaNs_Bz = np.argwhere(np.isnan(bz))\n",
    "\n",
    "        # If there are NaNs, replace with the average of surrounding couple of data points\n",
    "        for i in range(len(NaNs_Bx)):\n",
    "            bx[NaNs_Bx[i]] = np.nanmean(bx[NaNs_Bx[i-3]:NaNs_Bx[i+3]])\n",
    "            by[NaNs_By[i]] = np.nanmean(by[NaNs_By[i-3]:NaNs_By[i+3]])\n",
    "            bz[NaNs_Bz[i]] = np.nanmean(bz[NaNs_Bz[i-3]:NaNs_Bz[i+3]])                           \n",
    " \n",
    "    time = np.array(mag_arr['times'])\n",
    "    bx = np.array(pd.to_numeric(mag_arr['Bx']))\n",
    "    by = np.array(pd.to_numeric(mag_arr['By']))\n",
    "    bz = np.array(pd.to_numeric(mag_arr['Bz']))\n",
    "    \n",
    "    \n",
    "    # start and stop times of the magnetic field data from the .csv\n",
    "    n1 = mag_arr.date[0]\n",
    "    n2 = mag_arr.date[len(mag_arr.date)-1]\n",
    "\n",
    "     # Check if the start time is outside of the magnetic field timestamps by more than an hour\n",
    "    if m1 < n1:\n",
    "        print('WARNING!!! start time of current sheet =',m1, 'start time of B-field data =', n1)\n",
    "    if m1 > n2:\n",
    "        print('WARNING!!! start time of current sheet =',m1,'end time of B-field data =',n2)\n",
    "    if m2 > n2:\n",
    "        print('WARNING!!! end time of current sheet =',m2,'end time of B-field data =',n2)\n",
    "    if m2 < n1:\n",
    "        print('WARNING!!! end time of current sheet =',m2,'start time of B-field data =',n1)\n",
    "    \n",
    "    # search the B-field array date column for m1\n",
    "    v1 = mag_arr.date.searchsorted(m1)\n",
    "    v2 = mag_arr.date.searchsorted(m2)\n",
    "    \n",
    "    # as of 2024-03-28 if the value isn't in the array, searchsorted returns the closest value,\n",
    "    # e.g., if your looking for '2020-06-03/13:00:00' in an array that spans \n",
    "    # 2020-06-17/20:30:00 - 2020-06-18/01:30:00', searchsorted returns 0. If e.g., you're looking for\n",
    "    # '2024-06-03/13:00:00' it would return the last index in the array. Have to safe guard against this.\n",
    "    # Maybe specify if the element is more than an hour away from target, then the \n",
    "    # timestamp can't be found in the array.\n",
    "\n",
    "    bx = bx[v1:v2]\n",
    "    by = by[v1:v2]\n",
    "    bz = bz[v1:v2]\n",
    "\n",
    "    # ###################################\n",
    "    # # GET the Magnetic Variance Matrix#\n",
    "    # # eq. 8.8, p. 188 in reference    #\n",
    "    # ###################################\n",
    "\n",
    "\n",
    "    # magnetic variance matrix                                    \n",
    "    mm = np.zeros([3, 3])\n",
    "\n",
    "    bxa = np.mean(bx)\n",
    "    bya = np.mean(by)\n",
    "    bza = np.mean(bz)\n",
    "\n",
    "    print('0th moment of bx:',bxa)\n",
    "    print('0th moment of by:',bya)\n",
    "    print('0th moment of bz:',bza)\n",
    "\n",
    "    # #1st row\n",
    "    mm[0,0] = np.mean(bx*bx) - bxa*bxa\n",
    "    mm[1,0] = np.mean(bx*by) - bxa*bya\n",
    "    mm[2,0] = np.mean(bx*bz) - bxa*bza\n",
    "\n",
    "    # #2nd row\n",
    "    mm[0,1] = mm[1,0]\n",
    "    mm[1,1] = np.mean(by*by) - bya*bya\n",
    "    mm[2,1] = np.mean(by*bz) - bya*bza\n",
    "\n",
    "    # #3rd row\n",
    "    mm[0,2] = mm[2,0]\n",
    "    mm[1,2] = mm[2,1]\n",
    "    mm[2,2] = np.mean(bz*bz) - bza*bza\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('mm:',mm)\n",
    "\n",
    "    ##################################################################\n",
    "    ## GET EIGENVALUES and Eigenvectors of Magnetic Variance Matrix ##\n",
    "    ##################################################################\n",
    "    eigenvalues, eigenvectors = LA.eig(mm)    \n",
    "\n",
    "\n",
    "    idx = np.argsort(eigenvalues)\n",
    "    E_vals_sorted = eigenvalues[idx]\n",
    "    E_vec_sorted = eigenvectors[:,idx]\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('eigenvalues:')\n",
    "    print(E_vals_sorted)\n",
    "    print('eigenvectors:')                                   \n",
    "    print(E_vec_sorted)\n",
    "\n",
    "    # The eigenvector x1 corresponding to the smallest eigenvalue, λ1, \n",
    "    # is used as the estimator for the vector normal to the current sheet \n",
    "    # and λ1 itself represents the variance of the magnetic field component along the estimated normal.\n",
    "\n",
    "    # λ1's eigenvector is the vector normal to the CS.\n",
    "\n",
    "\n",
    "    # max variance -> λ3 -> L_hat* = x3\n",
    "\n",
    "    return E_vals_sorted,E_vec_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b8c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th moment of bx: 7.859658329687499\n",
      "0th moment of by: 1.482304751860113\n",
      "0th moment of bz: 8.310890515625\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mm: [[ 4.5157527   3.59586811 -2.87233924]\n",
      " [ 3.59586811  3.10864317 -2.48166863]\n",
      " [-2.87233924 -2.48166863  2.13095602]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "eigenvalues:\n",
      "[0.07462275 0.23540039 9.44532875]\n",
      "eigenvectors:\n",
      "[[-0.23083367 -0.69356434 -0.68241067]\n",
      " [ 0.7651781   0.30382417 -0.56762078]\n",
      " [ 0.60101439 -0.65319168  0.4605674 ]]\n"
     ]
    }
   ],
   "source": [
    "m1 = '2020-06-17/21:54:20'\n",
    "m2 = '2020-06-17/21:54:38'\n",
    "mag_arr_str = 'MMS2_B.csv'\n",
    "E_vals,E_vec = mms_mvab(m1,m2,mag_arr_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfd3684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are some lines of IDL code to get the cross-product normal.\n",
    "\n",
    "def Cross_product_normal(E_vals,E_vec,m1,m2,mag_arr_str):\n",
    "\n",
    "    mag_arr = pd.read_csv(mag_arr_str,header = 0,names = ['times','Bx','By','Bz','Bmag','date'],\n",
    "                         parse_dates=['date'])\n",
    "\n",
    "    m1 = pd.to_datetime(m1)\n",
    "    m2 = pd.to_datetime(m2)\n",
    "\n",
    "\n",
    "    # add check point to make sure eigenvectors are appropriate length/values\n",
    "\n",
    "    nv = E_vec[:,0]\n",
    "    #print('nv:',nv)\n",
    "    lv = E_vec[:,2]\n",
    "    #print('lv',lv)\n",
    "    mv = np.cross(nv,lv)\n",
    "\n",
    "    \n",
    "\n",
    "    rat = E_vals[1]/E_vals[0]\n",
    "\n",
    "    lxm = lv[0]\n",
    "    lym = lv[1]\n",
    "    lzm = lv[2]\n",
    "\n",
    "    mxm = mv[0]\n",
    "    mym = mv[1]\n",
    "    mzm = mv[2]\n",
    "\n",
    "    nxm = nv[0]\n",
    "    nym = nv[1]\n",
    "    nzm = nv[2]\n",
    "\n",
    "\n",
    "    # ##########################################################\n",
    "    # #Cross-Product Normal - get difference angles to MVAB LMN#\n",
    "    # ##########################################################\n",
    "\n",
    "    time = np.array(mag_arr['times'])\n",
    "    bx = np.array(pd.to_numeric(mag_arr['Bx']))\n",
    "    by = np.array(pd.to_numeric(mag_arr['By']))\n",
    "    bz = np.array(pd.to_numeric(mag_arr['Bz']))\n",
    "\n",
    "\n",
    "\n",
    "    # search the B-field array date column for m1\n",
    "    v1 = mag_arr.date.searchsorted(m1)\n",
    "    v2 = mag_arr.date.searchsorted(m2)\n",
    "\n",
    "\n",
    "    dtb = pd.Timedelta(hours = 0, minutes = 0, seconds = 2)\n",
    "\n",
    "\n",
    "    v1a = mag_arr.date.searchsorted(m1 - dtb)\n",
    "    v2a = mag_arr.date.searchsorted(m2 + dtb)\n",
    "\n",
    "    bv1x = bx[v1a:v1]\n",
    "    bv1y = by[v1a:v1]\n",
    "    bv1z = bz[v1a:v1]\n",
    "\n",
    "    bv2x = bx[v2:v2a]\n",
    "    bv2y = by[v2:v2a]\n",
    "    bv2z = bz[v2:v2a]\n",
    "    \n",
    "\n",
    "\n",
    "    bv1avg = [np.mean(bv1x),np.mean(bv1y),np.mean(bv1z)]\n",
    "\n",
    "    bv2avg = [np.mean(bv2x),np.mean(bv2y),np.mean(bv2z)]\n",
    "\n",
    "\n",
    "\n",
    "    bmag1 = np.sqrt(np.sum(np.multiply(bv1avg,bv1avg)))\n",
    "    bmag2 = np.sqrt(np.sum(np.multiply(bv2avg,bv2avg)))\n",
    "    #bshearcp = np.acos(sum(bv1avg*bv2avg)/(bmag1*bmag2))*180./!dpi\n",
    "    bshearcp = np.arccos(np.sum(np.multiply(bv1avg,bv2avg))/(bmag1*bmag2))*180\n",
    "\n",
    "\n",
    "\n",
    "    normal = np.cross(bv1avg,bv2avg)\n",
    "    normag = np.sqrt(np.sum(np.multiply(normal,normal)))\n",
    "    nc = normal/normag  # N-direction\n",
    "\n",
    "    # #Angle between cross-product & MVAB normals\n",
    "    #n12ang = np.arccos(np.sum(nv*nc))*180./!dpi\n",
    "    n12ang = np.arccos(np.sum(nv*nc))*180\n",
    "\n",
    "    \n",
    "\n",
    "    if n12ang >= 90.0:\n",
    "        nc = -nc\n",
    "\n",
    "    mvec = np.cross(nc,E_vec[:,2])\n",
    "    mmag = np.sqrt(np.sum(np.multiply(mvec,mvec)))\n",
    "    mc = mvec/mmag    #M-direction\n",
    "\n",
    "    lc = np.cross(mc,nc)  #L-direction\n",
    "    angle = np.arccos(np.sum(np.multiply(E_vec[:,2],lc)))*180\n",
    "\n",
    "\n",
    "\n",
    "    # Angle between cross-product & MVAB normals\n",
    "    n12ang = np.arccos(np.sum(np.multiply(nv,nc)))*180\n",
    "\n",
    "    \n",
    "    ###################################################\n",
    "    ## Use these print statements to make sure things are working correctly\n",
    "    ##\n",
    "    ###################################################\n",
    "    \n",
    "#     print('start time of current sheet:',m1,'\\n')\n",
    "#     print('end time of current sheet:',m2,'\\n')\n",
    "#     print('MVAB of N (GSE)',nv,'\\n')\n",
    "\n",
    "#     print('MVAB of L (GSE)',lv,'\\n')\n",
    "#     print('MVAB of M (GSE)',mv,'\\n')\n",
    "#     # average B-components from start_time - dtb to start time\n",
    "#     print('bv1avg',bv1avg,'\\n')\n",
    "#     print('Bgse1 (nT):',bv1avg,'\\n')\n",
    "#     print('Bgse2 (nT):',bv2avg,'\\n')\n",
    "#     print('Bshear (deg):',bshearcp,'\\n')\n",
    "#     # #Angle between cross-product & MVAB normals\n",
    "#     print('Nv*Nc =',n12ang,'\\n')\n",
    "#     # N-direction components?\n",
    "#     print('Ncp_gse: ',nc[0],nc[1],nc[2],'\\n')\n",
    "#     # L-direction components?\n",
    "#     print('Lcp_gse: ',lc[0],lc[1],lc[2],'\\n')\n",
    "#     # M-direction components? But not sure why they're in GSE\n",
    "#     print('Mcp_gse: ',mc[0],mc[1],mc[2],'\\n')\n",
    "    \n",
    "#     # print angle between cross-product &MVAB normals\n",
    "#     print('Nv*Nc =',n12ang,'\\n')\n",
    "\n",
    "    #bs2=bshear\n",
    "    lxc = lc[0]\n",
    "    lyc = lc[1]\n",
    "    lzc = lc[2]\n",
    "    mxc = mc[0]\n",
    "    myc = mc[1]\n",
    "    mzc = mc[2]\n",
    "    nxc = nc[0]\n",
    "    nyc = nc[1]\n",
    "    nzc = nc[2]\n",
    "    nang = n12ang\n",
    "\n",
    "    return nc,mc,lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f938c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc,mc,lc = Cross_product_normal(E_vals,E_vec,m1,m2,mag_arr_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44bbad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8567945301000445e-17\n",
      "1.2384516474336108e-17\n",
      "7.506839865497363e-18\n"
     ]
    }
   ],
   "source": [
    "# make sure the dot products are ~0\n",
    "\n",
    "print(np.dot(nc,lc))\n",
    "print(np.dot(mc,lc))\n",
    "print(np.dot(nc,mc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c7cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Using identification criteria from Eriksson et al., 2016\n",
    "# Vx jet candidates\n",
    "jet_candidate_timeranges = ['2020-06-17/22:01:38','2020-06-17/22:01:46']\n",
    "\n",
    "# 2020-06-17/22:16:55 - 2020-06-17/22:17:04\n",
    "# 2020-06-18/00:06:57 - 2020-06-18/00:07:02\n",
    "# 2020-06-18/00:15:36 - 2020-06-18/00:15:40 \n",
    "\n",
    "\n",
    "# # Vy jet candidates\n",
    "# 2020-06-17/21:35:56 - 2020-06-17/21:36:04\n",
    "# 2020-06-17/22:00:47 - 2020-06017/22:00:55 \n",
    "\n",
    "# # Vz jet candidates\n",
    "# 2020-06-17/21:16:35 - 2020-06-17/21:16:41\n",
    "\n",
    "# 2020-06-17/21:16:57 - 2020-06-17/21:17:05\n",
    "\n",
    "# 2020-06-17/21:42:47 - 2020-06-17/21:42:54 (Vz, possibly vy)\n",
    "\n",
    "# 2020-06-17/21:47:19 - 2020-06-17/21:47:30 ( Very asymmetric)\n",
    "\n",
    "# 2020-06-17/21:54:23 - 2020-06-17/21:54:25 \n",
    "\n",
    "# 2020-06-17/23:42:48 - 2020-06-17/23:42:57 (Possibly Vx candidate as well)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nc_mag = np.sqrt((np.sum(np.multiply(nc,nc))))\n",
    "\n",
    "lc_mag = np.sqrt((np.sum(np.multiply(lc,lc))))\n",
    "\n",
    "mc_mag = np.sqrt((np.sum(np.multiply(mc,mc))))\n",
    "\n",
    "# make sure the magnitudes are ~1\n",
    "\n",
    "print(nc_mag)\n",
    "print(lc_mag)\n",
    "print(mc_mag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bn = []\n",
    "bl = []\n",
    "bm = []\n",
    "\n",
    "mag_arr = pd.read_csv(mag_arr_str,header = 0,names = ['times','Bx','By','Bz','Bmag','date'],\n",
    "                         parse_dates=['date'])\n",
    "\n",
    "m1 = pd.to_datetime(jet_candidate_timeranges[0])\n",
    "m2 = pd.to_datetime(jet_candidate_timeranges[1])\n",
    "\n",
    "time = np.array(mag_arr['times'])\n",
    "bx = np.array(pd.to_numeric(mag_arr['Bx']))\n",
    "by = np.array(pd.to_numeric(mag_arr['By']))\n",
    "bz = np.array(pd.to_numeric(mag_arr['Bz']))\n",
    "\n",
    "\n",
    "\n",
    "# search the B-field array date column for m1\n",
    "v1 = mag_arr.date.searchsorted(m1)\n",
    "v2 = mag_arr.date.searchsorted(m2)\n",
    "\n",
    "bvx = bx[v1:v2]\n",
    "bvy = by[v1:v2]\n",
    "bvz = bz[v1:v2]\n",
    "time1 = time[v1:v2]\n",
    "\n",
    "\n",
    "\n",
    "print('number of data points to be examined:',len(time1),'\\n')\n",
    "# for each time stamp in the B-field from start and stop time of jet, find the new LMN components\n",
    "for t in range(len(time1)):\n",
    "    \n",
    "    # calculate cross product normals using eigen values, eigen vectors, and the start and stop \n",
    "    # time for each jet candidate. \n",
    "    nc,mc,lc = Cross_product_normal(E_vals,E_vec,jet_candidate_timeranges[0],\n",
    "                                          jet_candidate_timeranges[1],mag_arr_str)\n",
    "    \n",
    "    bvx_temp = bvx[t]\n",
    "    bvy_temp = bvy[t]\n",
    "    bvz_temp = bvz[t]\n",
    "    # create matrix where columns are the x,y,z component at that timestamp to be used in the following dot product\n",
    "    bvec = np.stack((bvx_temp,bvy_temp,bvz_temp), axis=-1)\n",
    "    \n",
    "    # find dot product between bvec and nc\n",
    "    bl.append(np.dot(bvec,lc))\n",
    "    bm.append(np.dot(bvec,mc))\n",
    "    bn.append(np.dot(bvec,nc))\n",
    "\n",
    "\n",
    "# print(bvec.ndim)\n",
    "# print(bvec.shape)\n",
    "# bn = np.dot(bvec,nc)\n",
    "# bl = np.dot(bvec,lc)\n",
    "# bm = np.dot(bvec,mc)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(time1,bl)\n",
    "plt.plot(time1,bm)\n",
    "plt.plot(time1,bn)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabdc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('$B_L$',bl,'\\n')\n",
    "print('$B_M$',bm,'\\n')\n",
    "print('$B_N$',bn,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea87cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib plotting\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "\n",
    "# Bx GSE\n",
    "ax_Bx = fig.add_subplot(911)\n",
    "#ax_Bx.set_title('Raw Data')\n",
    "#ax_Bx.plot(MMS2_B_trimmed['date'],MMS2_B_trimmed['Bx'], label='$B_x$', color ='black')\n",
    "ax_Bx.plot(MMS2_B['date'],MMS2_B['Bx'], label='$B_x$', color ='black')\n",
    "ax_Bx.set_ylabel('$B_x$ (GSE) \\n [nT]')\n",
    "ax_Bx.grid('on')\n",
    "#ax_Bx.set_xticklabels([])\n",
    "#ax_Bx.set_ylim([-50,50])\n",
    "\n",
    "#Vx GSE\n",
    "ax_Vx = fig.add_subplot(912,sharex = ax_Bx)\n",
    "#ax_Vx.set_title('Raw Data')\n",
    "ax_Vx.plot(MMS2_V['date'],MMS2_V['Vx'], label='$V_x$', color ='black')\n",
    "ax_Vx.set_ylabel('$V_x$ (GSE) \\n [km s$^{-1}$]')\n",
    "ax_Vx.grid('on')\n",
    "ax_Vx.set_ylim([-75,75])\n",
    "\n",
    "\n",
    "\n",
    "# By GSE\n",
    "ax_By = fig.add_subplot(913,sharex = ax_Bx)\n",
    "#ax_By.plot(MMS2_B_trimmed['date'],MMS2_B_trimmed['By'], label='$B_y$', color ='darkturquoise')\n",
    "ax_By.plot(MMS2_B['date'],MMS2_B['By'], label='$B_y$', color ='darkturquoise')\n",
    "ax_By.set_ylabel('$B_y$ (GSE) \\n [nT]')\n",
    "ax_By.grid('on')\n",
    "#ax_By.set_ylim([-50,50])\n",
    "\n",
    "#Vy GSE\n",
    "ax_Vy = fig.add_subplot(914,sharex = ax_Bx)\n",
    "ax_Vy.plot(MMS2_V['date'],MMS2_V['Vy'], label='$V_y$', color ='darkturquoise')\n",
    "ax_Vy.set_ylabel('$V_y$ (GSE) \\n [km s$^{-1}$]')\n",
    "ax_Vy.grid('on')\n",
    "#ax_Vy.set_ylim([-50,50]\n",
    "\n",
    "\n",
    "\n",
    "#Bz GSE\n",
    "ax_Bz = fig.add_subplot(915,sharex = ax_Bx)\n",
    "#ax_Bz.plot(MMS2_B_trimmed['date'],MMS2_B_trimmed['Bz'], label='$B_z$', color ='rebeccapurple')\n",
    "ax_Bz.plot(MMS2_B['date'],MMS2_B['Bz'], label='$B_z$', color ='rebeccapurple')\n",
    "ax_Bz.set_ylabel('$B_z$ (GSE) \\n [nT]')\n",
    "ax_Bz.grid('on')\n",
    "#ax_Bz.set_ylim([-50,50])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Vz GSE\n",
    "ax_Vz = fig.add_subplot(916,sharex = ax_Bx)\n",
    "ax_Vz.plot(MMS2_V['date'],MMS2_V['Vz'], label='$V_z$', color ='rebeccapurple')\n",
    "ax_Vz.set_ylabel('$V_z$ (GSE) \\n [km s$^{-1}$]')\n",
    "ax_Vz.grid('on')\n",
    "\n",
    "# ion density\n",
    "ax_n = fig.add_subplot(917,sharex = ax_Bx)\n",
    "ax_n.plot(MMS2_n['date'],MMS2_n['n'], label='$n$',color = 'maroon')\n",
    "ax_n.set_ylabel('n \\n [cm$^{-3}$]')\n",
    "ax_n.grid('on')\n",
    "#ax_n.set_xticklabels([])\n",
    "\n",
    "\n",
    "\n",
    "# ion parallel and perpendicular temperature\n",
    "ax_T = fig.add_subplot(918,sharex = ax_Bx)\n",
    "ax_T.plot(MMS2_Tperp['date'],MMS2_Tperp['Tperp'], label='$T_{⊥}$',color ='plum')\n",
    "ax_T.plot(MMS2_Tpara['date'],MMS2_Tpara['Tpara'], label='$T_{||}$',color ='seagreen')\n",
    "ax_T.set_ylabel('$T$ \\n [eV]')\n",
    "ax_T.grid('on')\n",
    "ax_T.legend(loc='center right',fontsize='small')\n",
    "\n",
    "\n",
    "\n",
    "# ax_IMF = fig.add_subplot(918,sharex = ax_Bx)\n",
    "# ax_IMF.plot(OMNI_IMF['date'],OMNI_IMF['IMF'], label='IMF',color ='darkgray')\n",
    "# #ax_IMF.plot(OMNI_flow_['date'],OMNI_IMF['IMF'], label='$T_{||}$',color ='seagreen')\n",
    "# ax_IMF.set_ylabel('IMF ')\n",
    "# ax_IMF.grid('on')\n",
    "# #x_IMF.legend(loc='center right',fontsize='small')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #ax1.set_xticks([])\n",
    "# plt.grid('on')\n",
    "# plt.legend()\n",
    "# ax2 = fig.add_subplot(512)\n",
    "# ax2.plot(MMS2_n['date'],MMS2_n['n'], label='$n$')\n",
    "# ax2.set_ylabel('n \\n [cm$^{-3}$]')\n",
    "# ax2.grid('on')\n",
    "# #ax2.set_xticks([])\n",
    "# #plt.grid('on')\n",
    "# ax3 = fig.add_subplot(513)\n",
    "# ax3.plot(MMS2_Tpara['date'],MMS2_Tpara['Tpara'], label='$T_{||}$')\n",
    "# ax3.set_ylabel('$T_{||}$ \\n [eV]')\n",
    "# ax3.grid('on')\n",
    "# #ax3.set_xticks([])\n",
    "# #plt.grid('on')\n",
    "# ax4 = fig.add_subplot(514)\n",
    "# ax4.plot(MMS2_Tperp['date'],MMS2_Tperp['Tperp'], label='$T_{⊥}$')\n",
    "# ax4.set_ylabel('$T_{⊥}$ \\n [eV]')\n",
    "# ax4.grid('on')\n",
    "# #ax4.set_xticks([])\n",
    "# #plt.grid('on')\n",
    "# ax5 = fig.add_subplot(515)\n",
    "# ax5.plot(MMS2_V['date'],MMS2_V['Vx'], label='$V_x$')\n",
    "# ax5.plot(MMS2_V['date'],MMS2_V['Vy'], label='$V_y$')\n",
    "# ax5.plot(MMS2_V['date'],MMS2_V['Vz'], label='$V_z$')\n",
    "# ax5.set_ylabel('$V}$ \\n [km s$^{-1}$]')\n",
    "# ax5.grid('on')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "#plt.legend()\n",
    "#plt.grid('on')\n",
    "\n",
    "plt.show()\n",
    "# plt.close()\n",
    "#fig.savefig('Full_time_period_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pySPEDAS)",
   "language": "python",
   "name": "pyspedas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
